\section{Esperimenti}

\subsection{Dataset utilizzati}
\subsubsection{LFM1b}


LFM1b\_artist è un dataset contenente informazioni riguardanti le interazioni tra utenti e artisti musicali.

\noindent Descrizione del dataset
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        \textbf{Caratteristica} & \textbf{Descrizione} \\
        \hline
        numero utenti & 120322 \\
        \hline
        numero items & 3123496 \\
        \hline
        numero interazioni & 65133026 \\
        \hline
        sparsità & 0.9998 \\
        \hline
        interazioni medie per utente & 541.3226 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul dataset LFM1b\_artist}
    \label{tab:dataset_info}
\end{table}


\noindent Descrizione del knowledge graph
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        numero entità testa & 823213 \\
        \hline
        numero entità coda & 353607 \\
        \hline
        numero relazioni & 8 \\
        \hline
        numero triple & 2114049 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul knowledge graph del dataset LFM1b\_artist}
    \label{tab:dataset_info}
\end{table}



\noindent\textbf{Descrizione procedimento di pre-processing}\\


\noindent Il dataset originale risultava essere troppo grande per le risorse a nostra disposizione, dunque è stato opportunamente processato. In paritcolare sono state svolte le seguenti operazioni
\begin{itemize}
    \item \textbf{Filtraggio:} il dataset è stato filtrato eliminando tutte le interazioni in cui erano coinvolti utenti e/o item con meno di 5 interazioni
    \item \textbf{Sampling:} dopo la fase di filtraggio, è stato effettuato un sampling casuale il cui scopo era quello di ridurre il numero di utenti e di item presenti. In particolare sono stati selezionati casualmente 20000 utenti e 50000 item e sono state mantenute solo le interazioni in cui erano coinvolti utenti e item selezionati
\end{itemize}

\noindent In questo modo è stato ottenuto un dataset più piccolo e più facilmente gestibile rispetto a quello originale.
Per poter lavorare su più dataset si è deciso di effettuare un ulteriore processing del dataset, andando a creare dei sampling con una strategia di stratificazione: \footnote{{{Mantenendo il numero di utenti inalterato per ognuno di essi sono stati campionati casualmente un determinato numero di interazioni cercando di mantenere inalterati i "rapporti originali" tra i diversi utenti}}}{}
\begin{itemize}
    \item \textbf{75\%:} Per ogni utente sono state mantenute il 75\% delle interazioni originali
    \item \textbf{50\%:} Dal dataset al 75\% sono state mantenute circa il 66.67\% delle interazioni di ogni utente, in modo tale da avere il 50\% delle interazioni originali
    \item \textbf{25\%:} Dal dataset al 50\% sono state mantenute il 50\% delle interazioni di ogni utente, in modo tale da avere il 25\% delle interazioni originali
\end{itemize}


\noindent\textbf{Dataset 20.000 users, 50.000 items}

\noindent Descrizione del dataset
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        \textbf{Caratteristica} & \textbf{Descrizione} \\
        \hline
        numero utenti & 19841 \\
        \hline
        numero items & 42457 \\
        \hline
        numero interazioni & 900212 \\
        \hline
        sparsità & 0.99893 \\
        \hline
        interazioni medie per utente & 45.3713 \\
        \hline
        interazioni medie per item & 21.2029 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul dataset LFM1b\_artist\_20U50I}
    \label{tab:dataset_info}
\end{table}


\noindent Descrizione del knowledge graph
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        numero entità testa & 15509 \\
        \hline
        numero entità coda & 35156 \\
        \hline
        numero relazioni & 5 \\
        \hline
        numero triple & 46827 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul knowledge graph del dataset LFM1b\_artist\_20U50I}
    \label{tab:dataset_info}
\end{table}

\noindent\textbf{Dataset 75\%}

\noindent Descrizione del dataset
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        \textbf{Caratteristica} & \textbf{Descrizione} \\
        \hline
        numero utenti & 19841 \\
        \hline
        numero items & 38932 \\
        \hline
        numero interazioni & 667850 \\
        \hline
        sparsità & 0.9991 \\
        \hline
        interazioni medie per utente & 33.66\\
        \hline
        interazioni medie per item & 17.15 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul dataset LFM1b\_artist\_20U50I\_75strat}
    \label{tab:dataset_info}
\end{table}


\noindent Descrizione del knowledge graph
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        numero entità testa & 14327 \\
        \hline
        numero entità coda & 32981 \\
        \hline
        numero relazioni & 5 \\
        \hline
        numero triple & 43559 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul knowledge graph del dataset LFM1b\_artist\_20U50I\_75strat}
    \label{tab:dataset_info}
\end{table}

\noindent\textbf{Dataset 50\%}

\noindent Descrizione del dataset
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        \textbf{Caratteristica} & \textbf{Descrizione} \\
        \hline
        numero utenti & 19841 \\
        \hline
        numero items & 33653 \\
        \hline
        numero interazioni & 440620 \\
        \hline
        sparsità &  0.9993 \\
        \hline
        interazioni medie per utente & 22.207 \\
        \hline
        interazioni medie per item & 13.093 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul dataset LFM1b\_artist\_20U50I\_50strat}
    \label{tab:dataset_info}
\end{table}


\noindent Descrizione del knowledge graph
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        numero entità testa & 12522 \\
        \hline
        numero entità coda & 29509 \\
        \hline
        numero relazioni & 5 \\
        \hline
        numero triple & 38491 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul knowledge graph del dataset LFM1b\_artist\_20U50I\_50strat}
    \label{tab:dataset_info}
\end{table}

\noindent\textbf{Dataset 25\%}

\noindent Descrizione del dataset
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        \textbf{Caratteristica} & \textbf{Descrizione} \\
        \hline
        numero utenti & 19841 \\
        \hline
        numero items & 24878 \\
        \hline
        numero interazioni & 218457 \\
        \hline
        sparsità & 0.9995 \\
        \hline
        interazioni medie per utente & 11.0103 \\
        \hline
        interazioni medie per item & 8.778 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul dataset LFM1b\_artist\_20U50I\_25strat}
    \label{tab:dataset_info}
\end{table}


\noindent Descrizione del knowledge graph
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        numero entità testa & 9444 \\
        \hline
        numero entità coda & 23463 \\
        \hline
        numero relazioni & 5 \\
        \hline
        numero triple & 29822 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul knowledge graph del dataset LFM1b\_artist\_20U50I\_25strat}
    \label{tab:dataset_info}
\end{table}

\subsubsection{Movielens-10m}
\noindent MovieLens10M è la versione a 10 milioni di interazioni del dataset MovieLens. In questo caso è stato aggiunto anche un KG con un hop pari a 1

\noindent Descrizione del dataset
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        \textbf{Caratteristica} & \textbf{Descrizione} \\
        \hline
        numero utenti & 69878 \\
        \hline
        numero items & 10677 \\
        \hline
        numero interazioni & 10000054 \\
        \hline
        sparsità & 0.98659 \\
        \hline
        interazioni medie per utente & 143.1073 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul dataset ml-10m}
    \label{tab:dataset_info}
\end{table}


\noindent Descrizione del knowledge graph
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        numero entità testa & 179775 \\
        \hline
        numero entità coda & 181868 \\
        \hline
        numero relazioni & 49 \\
        \hline
        numero triple & 1051385 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul knowledge graph del dataset ml-10m}
    \label{tab:dataset_info}
\end{table}




\noindent\textbf{Descrizione procedimento di pre-processing}\\


\noindent Il dataset originale risultava essere troppo grande per le risorse a nostra disposizione, dunque è stato opportunamente processato. In paritcolare sono state svolte le seguenti operazioni
\begin{itemize}
    \item \textbf{Filtraggio:} il dataset è stato filtrato eliminando tutte le interazioni in cui erano coinvolti utenti e/o item con meno di 5 interazioni
    \item \textbf{Sampling:} dopo la fase di filtraggio, è stato effettuato un sampling casuale il cui scopo era quello di ridurre il numero di utenti e di item presenti. In particolare sono stati selezionati casualmente 50000 utenti e 10000 item e sono state mantenute solo le interazioni in cui erano coinvolti utenti e item selezionati
\end{itemize}

\noindent In questo modo è stato ottenuto un dataset più piccolo e più facilmente gestibile rispetto a quello originale.

\noindent\textbf{Dataset con 50.000 utenti e 10.000 items}

\noindent Descrizione del dataset
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        \textbf{Caratteristica} & \textbf{Descrizione} \\
        \hline
        numero utenti & 50000 \\
        \hline
        numero items & 10000 \\
        \hline
        numero interazioni & 7053774 \\
        \hline
        sparsità & 0.9858 \\
        \hline
        interazioni medie per utente & 141.07548 \\
        \hline
        interazioni medie per item & 705.3774 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul dataset ml-10m\_50U10I}
    \label{tab:dataset_info}
\end{table}


\noindent Descrizione del knowledge graph
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        numero entità testa & 9937 \\
        \hline
        numero entità coda & 167042 \\
        \hline
        numero relazioni & 31 \\
        \hline
        numero triple & 521125 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul knowledge graph del dataset ml-10m\_50U10I}
    \label{tab:dataset_info}
\end{table}


\subsubsection{Movielens-1m}

\noindent MovieLens1M è la versione a 1 milione di interazioni del dataset MovieLens.

\noindent Descrizione del dataset
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        \textbf{Caratteristica} & \textbf{Descrizione} \\
        \hline
        numero utenti & 6040 \\
        \hline
        numero items & 3706 \\
        \hline
        numero interazioni & 1000209 \\
        \hline
        sparsità & 0.9553 \\
        \hline
        interazioni medie per utente & 165.5975 \\
        \hline
        interazioni medie per item & 269.8893 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul dataset ml-1m}
    \label{tab:dataset_info}
\end{table}

\noindent Descrizione del knowledge graph
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        numero entità testa & 78314 \\
        \hline
        numero entità coda & 79347 \\
        \hline
        numero relazioni & 49 \\
        \hline
        numero triple & 385923 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul knowledge graph del dataset ml-1m}
    \label{tab:dataset_info}
\end{table}


\subsubsection{Amazon-Book}

\noindent Amazon-Book è un dataset contenente informazioni riguardanti le interazioni tra utenti e libri.
In questo caso è stata usata direttamente una versione ridotta (quindi con pre-processing già effettuato) del dataset originale con un core di 60.

\noindent Descrizione del dataset
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        \textbf{Caratteristica} & \textbf{Descrizione} \\
        \hline
        numero utenti & 22155 \\
        \hline
        numero items & 54458 \\
        \hline
        numero interazioni & 1465871 \\
        \hline
        sparsità & 0.99878 \\
        \hline
        interazioni medie per utente & 66.1643\\
        \hline
        interazioni medie per item & 26.9205 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul dataset amazon\_books\_60core\_kg}
    \label{tab:dataset_info}
\end{table}

\noindent Descrizione del knowledge graph
\begin{table}[H]
    \centering
    \footnotesize
    \begin{tabularx}{\textwidth}{|c|X|}
        \hline
        numero entità testa & 26282 \\
        \hline
        numero entità coda & 26300 \\
        \hline
        numero relazioni & 16 \\
        \hline
        numero triple & 96476 \\
        \hline
    \end{tabularx}
    \caption{Informazioni sul knowledge graph del dataset amazon\_books\_60core\_kg}
    \label{tab:dataset_info}
\end{table}


\subsection{Esperimenti svolti}
\subsubsection{Benchmarking dei modelli}

La fase di benchmarking consiste nel continuare le ricerche già svolte in questo campo per poter confermare oppure smentire i risultati già ottenuti in passato.\\
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/situazione-attuale.png}
    \caption{Emissioni prodotte dai vari modelli}
\end{figure}

\noindent Gli esperimenti passati sono stati condotti su dataset e modelli presenti all'interno di RecBole.\\I dataset utilizzati per l'addestramento dei modelli sono:
\begin{itemize}
    \item \textbf{MovieLens-1M}
    \item \textbf{Amazon\_Book\_60core\_kg} 
    \item \textbf{Mind}
\end{itemize}

\noindent I modelli utilizzati per l'addestramento sono:
\begin{itemize}
    \item \textbf{BPR} \cite{BPR}: General
    \item \textbf{CDAE} \cite{CDAE}: General
    \item \textbf{CFKG} \cite{CFKG}: Knowledge
    \item \textbf{CKE} \cite{CKE}: Knowledge
    \item \textbf{DGCF} \cite{DGCF}: Knowledge
    \item \textbf{DMF} \cite{DMF}: General
    \item \textbf{DiffRec} \cite{DiffRec}: General
    \item \textbf{ENMF} \cite{ENMF}: General 
    \item \textbf{FISM} \cite{FISM}: General
    \item \textbf{GCMC} \cite{GCMC}: General
    \item \textbf{ItemKNN} \cite{ItemKNN}: General
    \item \textbf{KGCN} \cite{KGCN}: Knowledge
    \item \textbf{KGIN}: \cite{KGIN} Knowledge
    \item \textbf{KGNNLS} \cite{KGNNLS}: Knowledge
    \item \textbf{KTUP} \cite{KTUP}: Knowledge
    \item \textbf{LDiffRec} \cite{LDiffRec}: General
    \item \textbf{LINE} \cite{LINE}: General
    \item \textbf{LightGCN} \cite{LightGCN}: General
    \item \textbf{MKR} \cite{MKR}: Knowledge
    \item \textbf{MacridVAE} \cite{MacridVAE}: General
    \item \textbf{MultiDAE} \cite{MultiDAE}: General
    \item \textbf{MultiVAE} \cite{MultiVAE}: General
    \item \textbf{NCEPLRec} \cite{NCEPLRec}: General
    \item \textbf{NCL} \cite{NCL}: General
    \item \textbf{NGCF} \cite{NGCF}: General
    \item \textbf{NeuMF} \cite{NeuMF}: General
    \item \textbf{Pop}: General
    \item \textbf{Random}: General
    \item \textbf{RecVAE} \cite{RecVAE}: General
    \item \textbf{RippleNet} \cite{RippleNet}: Knowledge
    \item \textbf{SGL} \cite{SGL}: General
    \item \textbf{SLIMElastic} \cite{SLIMElastic}: General
    \item \textbf{SimpleX} \cite{SimpleX}: General
    \item \textbf{SpectralCF} \cite{SpectralCF}: General
    \item \textbf{EASE} \cite{EASE}: General
    \item \textbf{NAIS} \cite{NAIS}: General
    \item \textbf{ADMMSLIM} \cite{ADMMSLIM}: General
    \item \textbf{ConvNCF} \cite{ConvNCF}: General
    \item \textbf{NNCF} \cite{NNCF}: General
\end{itemize}

\noindent In questo ambito  Spillo et al.\cite{spillo2023towards} mostrano come spesso algoritmi più semplici riescono ad avere delle performance molto simili a modelli più complessi, ma con un impatto ambientale decisamente minore. Lo scopo di questo lavoro è dunque quello di confermare o smentire questi risultati.\\
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/sum_mind_dataset.png}
    \caption{Trade-off tra emissioni e performance con dataset Mind}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/sum_amazon_books_dataset.png}
    \caption{Trade-off tra emissioni e performance con dataset Amazon-Books}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{images/sum_movielens_dataset.png}
    \caption{Trade-off tra emissioni e performance con dataset MovieLens}
\end{figure}

\noindent RecBole richiede la definizione di un file di configurazione per poter addestrare i modelli. Questo file di configurazione contiene le seguenti informazioni:\\
\noindent \textbf{Parametri di environment} (servono per configurare l'ambiente di addestramento)
\begin{itemize}
    \item \textbf{gpu\_id}: 0
    \item \textbf{worker}: 0
    \item \textbf{use\_gpu}: True
    \item \textbf{seed}: 2020
    \item \textbf{state}: INFO
    \item \textbf{encoding}: utf-8
    \item \textbf{reproducibility}: True
    \item \textbf{shuffle}: True
\end{itemize}


\noindent \textbf{Parametri di training} (servono per l'addestramento dei modelli)
\begin{itemize}
    \item \textbf{epochs}: 200
    \item \textbf{train\_batch\_size}: 2048
    \item \textbf{learner}: adam
    \item \textbf{learning\_rate}: .001
    \item \textbf{train\_neg\_sample\_args}: 
    \begin{itemize}
        \item \textbf{distribution}: uniform
        \item \textbf{sample\_num}: 1
        \item \textbf{dynamic}: False
        \item \textbf{candidate\_num}: 0
    \end{itemize}
    \item \textbf{eval\_step}: 1
    \item \textbf{stopping\_step}: 10
    \item \textbf{clip\_grad\_norm}: None
    \item \textbf{loss\_decimal\_place}: 4
    \item \textbf{weight\_decay}: .0
    \item \textbf{require\_pow}: False
    \item \textbf{enable\_amp}: False
    \item \textbf{enable\_scaler}: False
\end{itemize}


\noindent \textbf{Parametri di evaluation} (servono per valutare i modelli)


\begin{itemize}
    \item \textbf{eval\_args}:
    \item \begin{itemize}
                \item \textbf{group\_by}: user
                \item \textbf{order}: RO
                \item \textbf{split}: RS : [0.8, 0.1, 0.1]
                \item \textbf{mode}: full
            \end{itemize}
    \item \textbf{repeatable}: False
    \item \textbf{metrics}: ['Recall', 'MRR', 'NDCG', 'Hit', 'MAP', 'Precision', 'GAUC', 'ItemCoverage', 'AveragePopularity', 'GiniIndex', 'ShannonEntropy', 'TailPercentage']
    \item \textbf{topk}: 10
    \item \textbf{valid\_metric}: MRR@10
    \item \textbf{eval\_batch\_size}: 4096
    \item \textbf{metric\_decimal\_place}: 4
\end{itemize}


\noindent \textbf{Iper parametri dei modelli}


\noindent Gli iper parametri dei modelli sono un insieme di parametri che vengono utilizzati per configurare i modelli. La loro configurazione può influenzare il risultato finale. Esistono delle tecniche di HyperTuning che permettono di trovare i migliori iper parametri per un determinato modello e dataset.
In questo caso si è scelto di utilizzare gli iper parametri di default per tutti i modelli.\\Per ognuno dei modelli a stato dell'arte scelti (prima elencati) sono stati effettuati run con i seguenti dataset:
\begin{itemize}
    \item \textbf{LFM1b\_artist\_20U50I}
    \item \textbf{LFM1b\_artist\_20U50I\_75strat}
    \item \textbf{LFM1b\_artist\_20U50I\_50strat}
    \item \textbf{LFM1b\_artist\_20U50I\_25strat}
    \item \textbf{ml-10m\_50U10I}
\end{itemize}

\noindent Dopo aver terminato le esecuzioni dei modelli sono stati creati dei grafici per poter confrontare i risultati ottenuti. I grafici sono i due tipi:
\begin{itemize}
    \item \textbf{Grafici a barre:} Questi grafici permettono di confrontare le emissioni dei vari modelli rispetto a ogni dataset.
    \item \textbf{Grafici a dispersione:} Questi dataset permettono di confrontare i trade-off tra emissioni e performance dei vari modelli rispetto a ogni dataset.
\end{itemize}

\noindent Per la valutazione dei modelli sono state utilizzate le seguenti metriche:
\begin{itemize}
    \item \textbf{Recall}: è una metrica che misura la capacità di un modello di raccomandare gli item rilevanti per un utente
    \item \textbf{NDCG}: è una metrica che misura la qualità delle raccomandazioni.
    \item \textbf{Gini Index}: è una metrica che misura l'equità nella distribuzione delle raccomandazioni. Un valore più vicino a zero indica una distribuzione più equa
    \item \textbf{Average Popularity}: è una metrica che misura la popolarità media degli item raccomandati. Un valore alto indica che le raccomandazioni sono concentrate su item popolari.
\end{itemize}



\subsubsection{Addestramento sostenibile}
L'addestramento sostenibile consiste nell'addestrare i modelli di recommendation in modo sostenibile, ovvero cercando di ridurre le emissioni di CO2 prodotte durante l'addestramento senza compromettere le performance dei modelli in modo significativo.
Si è dunque deciso di modificare il criterio di early stopping dei modelli inserendo come variabile anche le emissioni.
Il classico criterio di early stopping prevede di fermare l'addestramento del modello quando lo score ottenuto con il validation set non migliora per un certo numero di epoche consecutive.


\begin{figure}[H]
    \centering
     \includegraphics[width=\textwidth]{images/curve_emissions_score.png}
    \caption{Andamento dello score in funzione delle emissioni}
\end{figure}

\noindent Questa curva mostra mostra il comportamento dello score in funzione delle emissioni. In particolare si tiene traccia solo delle epoche in cui lo score è migliorato rispetto al risultato migliore.
Si può notare come la curva presenti una forte crescita iniziale, per poi stabilizzarsi e avere un andamento quasi lineare.
Questo andamento lineare indica dunque un miglioramento molto piccolo dello score rispetto all'aumento delle emissioni.

\noindent Il criterio di early stopping con emissioni si pone dunque come obiettivo quello di fermare l'addestramento del modello quando il miglioramento dello score rispetto alle emissioni è troppo piccolo.
L'idea alla base sarebbe quello di fermare l'addestramento studiando la derivata della curva. Siccome i valori sono discreti, si è deciso di approssimare la derivata con la differenza tra due punti consecutivi \cite{differenzedivise} mediante la seguente formula:
\begin{equation}
    \frac{f(x_{i+1}) - f(x_i)}{x_{i+1} - x_i}
\end{equation}

\noindent Quando la differenza tra due rapporti consecutivi è minore di una certa soglia, per un certo numero di volte consecutive, si ferma l'addestramento del modello.\\
\noindent\textbf{Parte esplorativa}\\
In questa parte si sono eseguti diversi esperimenti usando dataset diversi e parametri diversi per cercare di capire come il criterio di early stopping con emissioni influenzi le performance dei modelli in base ai parametri e alle dimensioni del dataset.\\
\begin{table}[h!]
    \centering
    \begin{tabularx}{\textwidth}{|c|X|c|X|}
    \hline
    \textbf{Esperimento} & \textbf{Dataset utilizzato} & \textbf{Soglia} & \textbf{Numero di Epoche Consecutive} \\
    \hline
    Primo esperimento & MovieLens-1m & 50 & 5 \\
    \hline
    Secondo esperimento & LFM-1b\_artist\_20U50I\_25strat & 30 & 7 \\
    \hline
    Terzo esperimento & amazon\_books\_60core\_kg & 40 & 6 \\
    \hline
    \end{tabularx}
    \caption{Dettagli degli esperimenti}
    \end{table}

\noindent Per ogni esperimento sono stati realizzati i seguenti grafici:
\begin{itemize}
    \item \textbf{Grafico delle emissioni}: confronta le emissioni prodotte dai vari modelli durante l'addestramento.
    \item \textbf{Grafico del trade-off}: mette in relazione il trade-off tra emissioni e performance dei modelli addestrati con il criterio di early stopping con emissioni e il trade-off dei modelli addestrati con il criterio di early stopping classico.
    \item \textbf{Grafico del decrementi performance}: mostra il decremento delle performance dei modelli addestrati con il criterio di early stopping con emissioni rispetto al criterio di early stopping classico.
\end{itemize}

Anche in questo caso sono state utilizzate le seguenti metriche per valutare i modelli:
\begin{itemize}
    \item \textbf{Recall}
    \item \textbf{NDCG}
    \item \textbf{Gini Index}
    \item \textbf{Average Popularity}
\end{itemize}

\noindent\textbf{Confronto tra i criteri di early stopping con emissioni}\\
In questa parte parte si è cercato di capire come i parametri del criterio di early stopping con emissioni influenzino le performance dei modelli.\\
Per fare ciò si è deciso di eseguire un esperimento con il dataset MovieLens-1m e di variare i parametri del criterio di early stopping con emissioni.\\
Gli esperimenti eseguti sono stati i seguenti:

\begin{table}[h!]
    \centering
    \begin{tabular}{|c|c|c|}
    \hline
    \textbf{Esperimento} & \textbf{Soglia} & \textbf{Numero di Epoche Consecutive} \\
    \hline
    Primo esperimento & 40 & 5 \\
    \hline
    Secondo esperimento & 30 & 5 \\
    \hline
    Terzo esperimento & 40 & 6 \\
    \hline
    Quarto esperimento & 30 & 6 \\
    \hline
    Quinto esperimento & 40 & 7 \\
    \hline
    Sesto esperimento & 30 & 7 \\
    \hline
    \end{tabular}
    \caption{Dettagli degli esperimenti}
\end{table}

\noindent Sono stati prodotti gli stessi grafici degli esperimenti precedenti per poter confrontare i risultati ottenuti. Sono state utilizzate le stesse metriche degli esperimenti precedenti per valutare i modelli.

\noindent\textbf{Studio della sensibilità dei parametri}\\
\noindent Per poter confrontare i risultati ottenuti e come i parametri influenzino le performance dei modelli sono stati realizzati dei grafici che mettono in relazione i trade-off tra emissioni e performance dei modelli addestrati con i diversi parametri del criterio di early stopping con emissioni, in modo da osservare la sensibilità dei parametri.
